# DRE Analytics 2025 - Pipeline ETL

Pipeline de dados para anÃ¡lise de DemonstraÃ§Ã£o do Resultado do ExercÃ­cio (DRE), com arquitetura Medallion (Bronze â†’ Silver â†’ Gold) e API REST.

## ğŸ“‹ VisÃ£o Geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DRE Analytics 2025 Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                           â”‚
â”‚  â”‚   Upload     â”‚  POST /api/v1/upload (Excel)                              â”‚
â”‚  â”‚   via API    â”‚                                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                           â”‚
â”‚         â”‚                                                                   â”‚
â”‚         â–¼                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚    Bronze    â”‚    â”‚    Silver    â”‚    â”‚     Gold     â”‚                   â”‚
â”‚  â”‚    (RAW)     â”‚ â”€â”€â–¶â”‚    (STG)     â”‚ â”€â”€â–¶â”‚     (DW)     â”‚                   â”‚
â”‚  â”‚  4 tabelas   â”‚    â”‚  4 tabelas   â”‚    â”‚ Star Schema  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                 â”‚                           â”‚
â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                            â–¼                    â–¼                    â–¼      â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                     â”‚   API REST   â”‚    â”‚   Power BI   â”‚    â”‚   Adminer  â”‚  â”‚
â”‚                     â”‚  GET /dre/*  â”‚    â”‚ DirectQuery  â”‚    â”‚  (SQL UI)  â”‚  â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Fluxo de Dados

1. **Upload via API** â†’ `POST /api/v1/upload` recebe Excel
2. **Pipeline ETL** â†’ Bronze â†’ Silver â†’ Gold (automÃ¡tico)
3. **Consumo** â†’ API REST ou Power BI conectado ao PostgreSQL

## ğŸ—ï¸ Estrutura do Projeto

```
dre_pipeline/
â”œâ”€â”€ api/                    # FastAPI REST
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py            # Endpoints
â”œâ”€â”€ etl/                    # Pipeline ETL
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ _00_config.py      # ConfiguraÃ§Ã£o
â”‚   â”œâ”€â”€ _01_extract_excel.py  # Bronze Layer
â”‚   â”œâ”€â”€ _02_transform_raw_to_stg.py  # Silver Layer
â”‚   â”œâ”€â”€ _03_transform_stg_to_dw.py   # Gold Layer
â”‚   â”œâ”€â”€ _04_dq_checks.py   # Data Quality
â”‚   â””â”€â”€ _05_run_pipeline.py  # Orquestrador
â”œâ”€â”€ sql/                    # DDL Scripts
â”‚   â”œâ”€â”€ 01_create_schemas.sql
â”‚   â”œâ”€â”€ 02_create_raw_tables.sql
â”‚   â”œâ”€â”€ 03_create_stg_tables.sql
â”‚   â”œâ”€â”€ 04_create_dw_tables.sql
â”‚   â””â”€â”€ 05_create_audit_tables.sql
â”œâ”€â”€ data/                   # Dados processados
â”œâ”€â”€ logs/                   # Logs de execuÃ§Ã£o
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o
â”œâ”€â”€ powerbi/               # Arquivos Power BI
â”œâ”€â”€ tests/                 # Testes
â”œâ”€â”€ config.yml             # ConfiguraÃ§Ã£o
â”œâ”€â”€ docker-compose.yml     # PostgreSQL
â”œâ”€â”€ requirements.txt       # DependÃªncias
â”œâ”€â”€ run_etl.bat           # Script Windows
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos

- Python 3.12+
- Docker Desktop
- Git

### 2. Setup do Ambiente

```bash
# Clone/navegue para o projeto
cd dre_pipeline

# Crie ambiente virtual
python -m venv venv

# Ative (Windows)
venv\Scripts\activate

# Ative (Linux/Mac)
source venv/bin/activate

# Instale dependÃªncias
pip install -r requirements.txt
```

### 3. Inicie o Banco de Dados

```bash
# Suba os containers (PostgreSQL + Adminer)
docker-compose up -d

# Verifique se estÃ¡ rodando
docker-compose ps
```

### 4. Configure o Projeto

```bash
# Copie o arquivo de configuraÃ§Ã£o de exemplo
cp config.yml.example config.yml

# Edite se necessÃ¡rio (credenciais padrÃ£o jÃ¡ funcionam com Docker)
```

### 5. Crie as Tabelas

```bash
# Conecte ao banco e execute os scripts SQL
# Via Adminer: http://localhost:8080
# Servidor: postgres | Usuario: dre_user | Senha: dre_pass | Banco: dre_db

# Ou via linha de comando
docker exec -i dre_postgres psql -U dre_user -d dre_db < sql/01_create_schemas.sql
docker exec -i dre_postgres psql -U dre_user -d dre_db < sql/02_create_raw_tables.sql
docker exec -i dre_postgres psql -U dre_user -d dre_db < sql/03_create_stg_tables.sql
docker exec -i dre_postgres psql -U dre_user -d dre_db < sql/04_create_dw_tables.sql
docker exec -i dre_postgres psql -U dre_user -d dre_db < sql/05_create_audit_tables.sql
```

### 6. Execute o Pipeline

```bash
# Via script (recomendado)
run_etl.bat

# Ou diretamente
python -m etl._05_run_pipeline
```

### 7. Inicie a API

```bash
# Inicie o servidor
uvicorn api.main:app --reload --port 8000

# Acesse a documentaÃ§Ã£o
# http://localhost:8000/docs
```

## ğŸ“Š Arquitetura de Dados

### Camada Bronze (RAW)

Dados brutos extraÃ­dos do Excel sem transformaÃ§Ã£o:

| Tabela | Origem | DescriÃ§Ã£o |
|--------|--------|-----------|
| `raw.receita` | Receita_Realizado + Receita_OrÃ§ | Receitas por unidade/mÃªs |
| `raw.despesa` | Despesas_Realizado + Despesas_OrÃ§ | Despesas por pacote/mÃªs |
| `raw.dre` | Modelo DRE | Linhas da DRE |
| `raw.aliquota` | Aliquotas | Impostos por tipo |

### Camada Silver (STG)

Dados limpos e normalizados:

| Tabela | TransformaÃ§Ãµes |
|--------|----------------|
| `stg.receita` | Unpivot meses, padronizaÃ§Ã£o nomes |
| `stg.despesa` | Unpivot meses, limpeza pacotes |
| `stg.dre` | Unpivot meses, categorizaÃ§Ã£o |
| `stg.aliquota` | NormalizaÃ§Ã£o percentuais |

### Camada Gold (DW)

Star Schema otimizado para anÃ¡lise:

**DimensÃµes:**
- `dim_calendario` - Meses do ano
- `dim_unidade` - Unidades de negÃ³cio
- `dim_tipo_receita` - SALES, SERVICE
- `dim_cenario` - Realizado, OrÃ§ado
- `dim_pacote` - Pacotes de despesas
- `dim_linha_dre` - Linhas da DRE

**Fatos:**
- `fact_receita` - Receitas mensais
- `fact_despesa` - Despesas mensais
- `fact_dre` - DRE consolidada
- `fact_aliquota` - AlÃ­quotas de impostos

## ğŸ” Data Quality

O pipeline inclui 12 validaÃ§Ãµes automÃ¡ticas:

| Regra | DescriÃ§Ã£o | Threshold |
|-------|-----------|-----------|
| `receita_realizado_total` | Soma receita realizada | ~67.6M |
| `receita_orcado_total` | Soma receita orÃ§ada | ~68.4M |
| `despesas_realizado_total` | Soma despesas realizadas | ~-41.6M |
| `lucro_liquido_dre` | Lucro lÃ­quido DRE | ~18.6M |
| `all_months_present` | 12 meses na dim_calendario | 12 |
| `fact_receita_not_empty` | fact_receita tem dados | >0 |
| `service_greater_sales` | SERVICE > SALES | True |

## ğŸŒ API Endpoints

### IngestÃ£o (entrada de dados)

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| POST | `/api/v1/upload` | **Upload de Excel** â†’ dispara pipeline |
| POST | `/api/v1/pipeline/run` | Executa pipeline manualmente |

### Consulta (leitura de dados)

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| GET | `/api/v1/health` | Status do sistema |
| GET | `/api/v1/dre` | Resumo DRE (totais anuais) |
| GET | `/api/v1/dre/mensal` | DRE detalhado por mÃªs |
| GET | `/api/v1/receita` | Receitas por tipo/cenÃ¡rio |
| GET | `/api/v1/despesa` | Top despesas por pacote |

### Exemplo de Uso

```bash
# Upload de novo arquivo Excel
curl -X POST "http://localhost:8000/api/v1/upload" \
     -F "file=@dados_case_pbi.xlsx"

# Consultar DRE
curl "http://localhost:8000/api/v1/dre"
```

## â° Agendamento (Windows Task Scheduler)

1. Abra o **Agendador de Tarefas**
2. Criar Tarefa BÃ¡sica
3. Configure:
   - **Trigger:** DiÃ¡rio Ã s 06:00
   - **AÃ§Ã£o:** Iniciar programa
   - **Programa:** `C:\...\dre_pipeline\run_etl.bat`
   - **Argumentos:** `auto`
   - **Iniciar em:** `C:\...\dre_pipeline`

## ğŸ“ Dados de Origem

O arquivo fonte Ã© `dados_case_pbi.xlsx` com 6 abas:

| Aba | Linhas | Colunas | DescriÃ§Ã£o |
|-----|--------|---------|-----------|
| Receita_Realizado | 89 | 14 | Receitas realizadas |
| Receita_OrÃ§ | 90 | 14 | Receitas orÃ§adas |
| Despesas_Realizado | 46 | 15 | Despesas realizadas |
| Despesas_OrÃ§ | 46 | 15 | Despesas orÃ§adas |
| Modelo DRE | 98 | 17 | Estrutura DRE |
| Aliquotas | 17 | 3 | AlÃ­quotas impostos |

## ğŸ”§ Desenvolvimento

```bash
# Testes
pytest tests/

# FormataÃ§Ã£o
black etl/ api/
isort etl/ api/

# Type checking
mypy etl/ api/
```

## ğŸ“ Logs

Os logs sÃ£o salvos em `logs/` com formato:
```
etl_YYYYMMDD_HHMMSS.log
```

## ğŸ³ Docker Services

| ServiÃ§o | Porta | DescriÃ§Ã£o |
|---------|-------|-----------|
| postgres | 5432 | PostgreSQL 15 |
| adminer | 8080 | UI Admin SQL |

## ğŸ“ Suporte

Para dÃºvidas ou problemas, consulte a documentaÃ§Ã£o em `docs/` ou abra uma issue.

---

**VersÃ£o:** 1.0.0  
**Ãšltima atualizaÃ§Ã£o:** 2025
